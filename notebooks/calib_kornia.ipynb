{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import cv2\n",
    "from scipy.signal import convolve2d\n",
    "from typing import List\n",
    "from optim_correspondance import load_src_and_dest, fix_timing_between_left_and_right, save_each_frame_to_separate_file\n",
    "from utils.homography import HomographySIFT, HomographyResult\n",
    "import torch\n",
    "from utils.constants import NORM_GL, DENORM_GL, U100C2C\n",
    "from utils.image_stitcher import make_gif_of_sequence\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "\n",
    "path_to_files = Path('rawData') / 'calib'\n",
    "src, dest = load_src_and_dest(path_to_files=path_to_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME_DIFF = 0.001  # seconds\n",
    "src, dest = fix_timing_between_left_and_right(src=src, dest=dest,\n",
    "                                              max_time_diff=MAX_TIME_DIFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_each_frame_to_separate_file(src=src, dest=dest, path_to_files=path_to_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_between_centers_of_cameras = 0.1  # meters   ?????????????????????????????????????????\n",
    "distance_from_ground = 50 # meters\n",
    "focal_length = 9.8 * 1e-3 # meters\n",
    "size_of_pixel = 17 * 1e-6 # meters\n",
    "image_width = 336 # pixels\n",
    "image_height = 256 # pixels\n",
    "\n",
    "delta_distance_from_ground = 3 # meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov_width_rad = 2 * np.arctan(image_width * size_of_pixel / (2 * focal_length))\n",
    "fov_width_degree = fov_width_rad * 180 / np.pi\n",
    "fov_width_meters = 2 * distance_from_ground * np.tan(fov_width_rad / 2)\n",
    "fov_height_rad = 2 * np.arctan(image_height * size_of_pixel / (2 * focal_length))\n",
    "fov_height_degree = fov_height_rad * 180 / np.pi\n",
    "fov_height_meters = 2 * distance_from_ground * np.tan(fov_height_rad / 2)\n",
    "print(f\"FOV width: {fov_width_degree:.1f}deg, {fov_width_meters:.1f}m\")\n",
    "print(f\"FOV height: {fov_height_degree:.1f}deg, {fov_height_meters:.1f}m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov_single_pixel_width_meters = 2 * distance_from_ground * size_of_pixel / focal_length\n",
    "fov_single_pixel_height_meters = 2 * distance_from_ground * size_of_pixel / focal_length\n",
    "print(f\"FOV single pixel width: {fov_single_pixel_width_meters:.2g}m\")\n",
    "print(f\"FOV single pixel height: {fov_single_pixel_height_meters:.2g}m\")\n",
    "\n",
    "min_fov_change = 2 * (distance_from_ground-delta_distance_from_ground) * size_of_pixel / focal_length\n",
    "max_fov_change = 2 * (distance_from_ground+delta_distance_from_ground) * size_of_pixel / focal_length\n",
    "print(f\"Min FOV change: {min_fov_change:.2g}m\")\n",
    "print(f\"Max FOV change: {max_fov_change:.2g}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_between_cameras_in_pixels = distance_between_centers_of_cameras / fov_single_pixel_width_meters\n",
    "print(f\"Distance between cameras in pixels: {distance_between_cameras_in_pixels:.2g} pixels\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first frame side-by-side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].imshow(src['frames'][0])\n",
    "ax[1].imshow(dest['frames'][0])\n",
    "ax[0].set_title('Left camera')\n",
    "ax[1].set_title('Right camera')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try finding the homography using cv2 on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cv2 to find the homography between the frames\n",
    "\n",
    "def find_homography(left, right):\n",
    "    left = cv2.normalize(left, left, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    right = cv2.normalize(right, right, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(left, None)\n",
    "    kp2, des2 = orb.detectAndCompute(right, None)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    return M, mask\n",
    "find_homography(src['frames'][0].copy(), dest['frames'][0].copy())[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute force search using Kornia\n",
    "Better results than cv2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "\n",
    "with torch.inference_mode():\n",
    "    homography = HomographySIFT().to(DEVICE, dtype=torch.float32)\n",
    "    x = np.concatenate([src['frames'][None], dest['frames'][None]], axis=0).transpose(1, 0, 2, 3).copy()\n",
    "    x = NORM_GL(x.astype(float))\n",
    "    x = torch.from_numpy(x)\n",
    "    ret_val: List[HomographyResult] = [homography(x=x_.to(DEVICE, dtype=torch.float32), m=None, mask=None, verbose=False).cpu() for x_ in tqdm(torch.split(x, 1, dim=0))]\n",
    "h_list = np.concatenate([p.homography for p in ret_val], 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Kornia results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, j in np.ndindex(3, 3):\n",
    "#     d = h_list[:, i, j]\n",
    "#     std = np.std(d)\n",
    "#     d = d[np.abs(d - np.mean(d)) < 1 * std]\n",
    "#     if len(d) == 0:\n",
    "#         print(f'({i}, {j}) has no data')\n",
    "#         continue\n",
    "#     plt.figure()\n",
    "#     plt.scatter(range(len(d)), d, label='y', s=2)\n",
    "#     plt.plot(np.mean(d) * np.ones_like(d), label='mean', c='r', linewidth=1)\n",
    "#     plt.title(f'({i}, {j}), std={d.std():.3g}, mean={np.mean(d):.2g}')\n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(h_list))\n",
    "np.random.shuffle(indices)\n",
    "indices = indices[:10]\n",
    "for idx in indices:\n",
    "    src_ = src['frames'][idx]\n",
    "    dest_ = dest['frames'][idx]\n",
    "    h = ret_val[idx].homography.numpy().squeeze()\n",
    "    warped = cv2.warpPerspective(src_, h, (src_.shape[1], src_.shape[0])).astype(float)\n",
    "    mask = cv2.warpPerspective(np.ones_like(src_), h, (src_.shape[1], src_.shape[0])).astype(bool)\n",
    "    kernel_size = 5\n",
    "    mask = (convolve2d(mask.astype(float), np.ones((kernel_size, kernel_size)), mode='same') // kernel_size ** 2).astype(bool)\n",
    "    warped[~mask] = np.nan\n",
    "\n",
    "    # plot the first frame side-by-side\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    ax[0].imshow(src_)\n",
    "    ax[0].set_title(f'src {np.ptp(src_)=:.0f}')\n",
    "    ax[0].axhline(src_.shape[0] // 2, c='r', linewidth=1)\n",
    "    ax[1].imshow(dest_)\n",
    "    ax[1].set_title(f'dest {np.ptp(dest_)=:.0f}')\n",
    "    ax[1].axhline(dest_.shape[0] // 2, c='r', linewidth=1)\n",
    "    ax[2].imshow(warped, vmin=warped[mask].min(), vmax=warped[mask].max())\n",
    "    ax[2].set_title(f'Warped {np.ptp(warped[mask])=:.0f}')\n",
    "    ax[2].axhline(warped.shape[0] // 2, c='r', linewidth=1)\n",
    "\n",
    "    # Calculate the difference between the static and the warped image\n",
    "    # dest_ = dest_.astype(float)\n",
    "    # warped = warped.astype(float)\n",
    "    # dest_ = (dest_ - dest_.min()) / (dest_.max() - dest_.min())\n",
    "    # warped = (warped - np.nanmin(warped)) / (np.nanmax(warped) - np.nanmin(warped))\n",
    "    diff = np.abs(dest_ - warped)\n",
    "\n",
    "    # Add colorbar to ax[3]\n",
    "    divider = make_axes_locatable(ax[3])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(ax[3].imshow(diff), cax=cax)\n",
    "    ax[3].set_title(f'Diff, avg err: {np.nanmean(diff):4.0f}GL')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
