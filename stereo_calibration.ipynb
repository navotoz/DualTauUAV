{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import cv2\n",
    "from typing import List\n",
    "from utils.homography import HomographySIFT, HomographyResult\n",
    "import torch\n",
    "from utils.constants import NORM_GL, DENORM_GL, U100C2C\n",
    "from utils.image_stitcher import make_gif_of_sequence\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "\n",
    "\n",
    "def load_files_from_dir(path):\n",
    "    data = {}\n",
    "    list_files = list(path.glob('*.npz'))\n",
    "    for p in list_files:\n",
    "        try:\n",
    "            d = np.load(p)\n",
    "        except:\n",
    "            continue\n",
    "        for k, v in d.items():\n",
    "            data.setdefault(k, []).extend( v)\n",
    "    if not data:\n",
    "        try:\n",
    "            data = np.load(path.with_suffix('.npz'))\n",
    "        except:\n",
    "            raise FileNotFoundError(f'No files found in {path}')\n",
    "    indices = np.argsort(data['time_ns'])\n",
    "    data = {k:np.stack(v)[indices] for k, v in data.items()}\n",
    "    return data\n",
    "\n",
    "\n",
    "path_to_files = Path('')\n",
    "\n",
    "left = load_files_from_dir(path_to_files / 'pan')\n",
    "right = load_files_from_dir(path_to_files / 'mono')\n",
    "\n",
    "print(f\"List of keys in dict: {list(right.keys())}\\n\")\n",
    "print(f\"Number of left frames: {len(left['time_ns']):,}\")\n",
    "print(f\"Number of right frames: {len(right['time_ns']):,}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix timing between stereo cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME_DIFF = 0.0003  # seconds\n",
    "\n",
    "def _get_diff(left, right):\n",
    "    if len(left['time_ns']) > len(right['time_ns']):\n",
    "        return np.abs(left['time_ns'][:, None] - right['time_ns'][None, :])\n",
    "    else:\n",
    "        return np.abs(left['time_ns'][None, :] - right['time_ns'][:, None])\n",
    "diff_before = _get_diff(left, right).argmin(0)\n",
    "\n",
    "# Remove frames that are not in both cameras\n",
    "while abs(len(left['time_ns']) - len(right['time_ns'])) > 1:\n",
    "    # Find the difference between the timestamps of the two cameras\n",
    "    diff = _get_diff(left, right)\n",
    "\n",
    "    # Find the indices in the longer array that have no counterpart in the shorter array\n",
    "    diff_values_of_longer_dict = np.min(diff, axis=1)\n",
    "    mask_longer_dict = diff_values_of_longer_dict <= (MAX_TIME_DIFF * 1e9)\n",
    "    indices_of_longer_dict = np.where(mask_longer_dict)[0]\n",
    "    if len(left['time_ns']) > len(right['time_ns']):\n",
    "        left = {k: v[indices_of_longer_dict] for k, v in left.items()}\n",
    "    else:\n",
    "        right = {k: v[indices_of_longer_dict] for k, v in right.items()}\n",
    "print(f\"Length of left: {len(left['time_ns']):,}\")\n",
    "print(f\"Length of right: {len(right['time_ns']):,}\")\n",
    "\n",
    "# Sort both arrays to have the closest timestamps have same index\n",
    "diff = np.argmin(np.abs(left['time_ns'][:, None] - right['time_ns'][None, :]), axis=0)\n",
    "left = {k: v[diff] for k, v in left.items()}\n",
    "\n",
    "diff = np.abs(left['time_ns'] - right['time_ns'])*1e-9\n",
    "print(f\"Max time difference between frames: {np.max(diff):.2g} seconds\")\n",
    "print(f\"Min time difference between frames: {np.min(diff):.2g} seconds\")\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(range(len(left['time_ns'])), left['time_ns'] * 1e-9, label='Left', s=2)\n",
    "plt.scatter(range(len(right['time_ns'])), right['time_ns'] * 1e-9, label='Right', s=2)\n",
    "plt.title('Timestamps of frames')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(range(len(diff)), diff, c='r', s=2)\n",
    "plt.plot(np.ones_like(left['time_ns'])*np.mean(diff))\n",
    "plt.grid()\n",
    "plt.title('Time difference between frames')\n",
    "plt.ylabel('Time difference [s]')\n",
    "plt.show()\n",
    "\n",
    "# diff = _get_diff(left, right)\n",
    "# plt.figure()\n",
    "# plt.plot(diff.argmin(0), label='After')\n",
    "# plt.plot(diff_before, label='Before')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "# diff = left['time_ns'] - right['time_ns']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_between_centers_of_cameras = 0.1  # meters   ?????????????????????????????????????????\n",
    "distance_from_ground = 50 # meters\n",
    "focal_length = 9.8 * 1e-3 # meters\n",
    "size_of_pixel = 17 * 1e-6 # meters\n",
    "image_width = 336 # pixels\n",
    "image_height = 256 # pixels\n",
    "\n",
    "delta_distance_from_ground = 3 # meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov_width_rad = 2 * np.arctan(image_width * size_of_pixel / (2 * focal_length))\n",
    "fov_width_degree = fov_width_rad * 180 / np.pi\n",
    "fov_width_meters = 2 * distance_from_ground * np.tan(fov_width_rad / 2)\n",
    "fov_height_rad = 2 * np.arctan(image_height * size_of_pixel / (2 * focal_length))\n",
    "fov_height_degree = fov_height_rad * 180 / np.pi\n",
    "fov_height_meters = 2 * distance_from_ground * np.tan(fov_height_rad / 2)\n",
    "print(f\"FOV width: {fov_width_degree:.1f}deg, {fov_width_meters:.1f}m\")\n",
    "print(f\"FOV height: {fov_height_degree:.1f}deg, {fov_height_meters:.1f}m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov_single_pixel_width_meters = 2 * distance_from_ground * size_of_pixel / focal_length\n",
    "fov_single_pixel_height_meters = 2 * distance_from_ground * size_of_pixel / focal_length\n",
    "print(f\"FOV single pixel width: {fov_single_pixel_width_meters:.2g}m\")\n",
    "print(f\"FOV single pixel height: {fov_single_pixel_height_meters:.2g}m\")\n",
    "\n",
    "min_fov_change = 2 * (distance_from_ground-delta_distance_from_ground) * size_of_pixel / focal_length\n",
    "max_fov_change = 2 * (distance_from_ground+delta_distance_from_ground) * size_of_pixel / focal_length\n",
    "print(f\"Min FOV change: {min_fov_change:.2g}m\")\n",
    "print(f\"Max FOV change: {max_fov_change:.2g}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_between_cameras_in_pixels = distance_between_centers_of_cameras / fov_single_pixel_width_meters\n",
    "print(f\"Distance between cameras in pixels: {distance_between_cameras_in_pixels:.2g} pixels\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first frame side-by-side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].imshow(left['frames'][0])\n",
    "ax[1].imshow(right['frames'][0])\n",
    "ax[0].set_title('Left camera')\n",
    "ax[1].set_title('Right camera')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try finding the homography using cv2 on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cv2 to find the homography between the frames\n",
    "\n",
    "def find_homography(left, right):\n",
    "    left = cv2.normalize(left, left, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    right = cv2.normalize(right, right, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(left, None)\n",
    "    kp2, des2 = orb.detectAndCompute(right, None)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    return M, mask\n",
    "find_homography(left['frames'][0], right['frames'][0])[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute force search for the best homography\n",
    "Results were not that good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def warp_image(img, M):\n",
    "#     return cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "# def _calc_loss(M, left, right):\n",
    "#     loss = 0\n",
    "#     for idx in range(len(left['frames'])):\n",
    "#         estimated_right = warp_image(left['frames'][idx], M)\n",
    "#         loss += np.mean(np.abs((estimated_right - right['frames'][idx])))\n",
    "#     loss /= len(left['frames'])\n",
    "#     return loss\n",
    "\n",
    "\n",
    "# NW = 100\n",
    "# NH = 100\n",
    "# array_distances_w = np.linspace(0.9, 2, NW)\n",
    "# array_distances_h = np.linspace(5.5, 7, NH)\n",
    "# M_permutations = np.eye(3)[None, None]\n",
    "# M_permutations = M_permutations.repeat(NH, axis=0).repeat(NW, axis=1)\n",
    "# M_permutations[:, :, 0, 2] = array_distances_h[:, None]\n",
    "# M_permutations[:, :, 1, 2] = array_distances_w[None, :]\n",
    "# M_permutations = M_permutations.reshape(-1, 3, 3)\n",
    "\n",
    "# func = partial(_calc_loss, left=left.copy(), right=right.copy())\n",
    "\n",
    "\n",
    "# with mp.Pool(mp.cpu_count()) as pool:\n",
    "#     ret_val = list(tqdm(pool.imap(func, M_permutations, \n",
    "#                                   chunksize=2**6), \n",
    "#                                 #   chunksize=len(M_permutations) // mp.cpu_count()), \n",
    "#                                   total=len(M_permutations)))\n",
    "\n",
    "# print(min(ret_val))\n",
    "# print(M_permutations[np.argmin(ret_val)])\n",
    "# plt.plot(ret_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute force search using Kornia\n",
    "Better results than cv2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "\n",
    "with torch.inference_mode():\n",
    "    homography = HomographySIFT().to(DEVICE, dtype=torch.float32)\n",
    "    x = np.concatenate([left['frames'][None], right['frames'][None]], axis=0).transpose(1, 0, 2, 3)\n",
    "    x = NORM_GL(x.astype(float))\n",
    "    x = torch.from_numpy(x)\n",
    "    ret_val: List[HomographyResult] = [homography(x=x_.to(DEVICE, dtype=torch.float32), m=None, mask=None, verbose=False).cpu() for x_ in tqdm(torch.split(x, 1, dim=0))]\n",
    "h = np.concatenate([p.homography for p in ret_val], 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Kornia results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in np.ndindex(3, 3):\n",
    "    d = h[:, i, j]\n",
    "    std = np.std(d)\n",
    "    d = d[np.abs(d - np.mean(d)) < 1 * std]\n",
    "    plt.figure()\n",
    "    plt.scatter(range(len(d)), d, label='y', s=2)\n",
    "    plt.plot(np.mean(d) * np.ones_like(d), label='mean', c='r', linewidth=1)\n",
    "    # plt.plot(np.mean(d) * np.ones_like(d)-1,  '--', c='black', linewidth=1)\n",
    "    # plt.plot(np.mean(d) * np.ones_like(d])+1,  '--', c='black', linewidth=1)\n",
    "    # plt.yticks(np.arange(np.floor(d.min()), np.ceil(d.max()), 1))\n",
    "    plt.title(f'Homography {i}, {j}')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(h))\n",
    "np.random.shuffle(indices)\n",
    "indices = indices[:10]\n",
    "for idx in indices:\n",
    "    static = U100C2C(DENORM_GL(ret_val[idx].static.squeeze()))\n",
    "    dynamic = U100C2C(DENORM_GL(ret_val[idx].dynamic.squeeze()))\n",
    "    warped = U100C2C(DENORM_GL(ret_val[idx].warped.squeeze()))\n",
    "    mask = ret_val[idx].mask.squeeze().float()\n",
    "\n",
    "    # Erode the mask to remove border artifacts\n",
    "    SIZE_OF_EROSION = 9\n",
    "    mask = torch.nn.functional.conv2d(\n",
    "        mask[None, None],\n",
    "        torch.ones(1, 1, SIZE_OF_EROSION, SIZE_OF_EROSION).to(mask),\n",
    "        padding=SIZE_OF_EROSION // 2).squeeze()\n",
    "    mask /= SIZE_OF_EROSION**2\n",
    "    mask = mask == 1\n",
    "\n",
    "    # plot the first frame side-by-side\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    ax[0].imshow(static)\n",
    "    ax[0].set_title('Static')\n",
    "    ax[1].imshow(dynamic)\n",
    "    ax[1].set_title('Dynamic')\n",
    "    ax[2].imshow(warped, vmin=warped[mask].min(), vmax=warped[mask].max())\n",
    "    ax[2].set_title('Warped')\n",
    "\n",
    "    # Calculate the difference between the static and the warped image\n",
    "    diff = np.abs(static - warped)\n",
    "    vmin = diff[mask].min()\n",
    "    vmax = diff[mask].max()\n",
    "    diff[~mask] = -1\n",
    "    ax[3].imshow(diff, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    # Add colorbar to ax[3]\n",
    "    divider = make_axes_locatable(ax[3])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(ax[3].imshow(diff, vmin=diff[mask].min(), vmax=diff[mask].max()), cax=cax)\n",
    "    ax[3].set_title(f'Diff, avg err: {diff[mask].mean():.2g}C')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = Path('rawData')\n",
    "path_to_save.mkdir(exist_ok=True)\n",
    "\n",
    "for idx, frame in enumerate(left['frames']):\n",
    "    np.save(path_to_save / f'left_{idx}.npy', frame)\n",
    "for idx, frame in enumerate(right['frames']):\n",
    "    np.save(path_to_save / f'right_{idx}.npy', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
